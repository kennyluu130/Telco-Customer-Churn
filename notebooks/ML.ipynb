{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMlnOcZ8msJ"
      },
      "source": [
        "# Machine Learning for Telco Customer Churn Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErqVQ-Xd8rk2"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wPmlY7XT6f7L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1uE2D7aV9sqS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RaHQR2yV97Db"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3qa6nDsX_M8Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kemin\\Documents\\Projects\\Telco-Customer-Churn\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfVe0awO_ZRt",
        "outputId": "23404fd6-9afa-4b9d-d474-02b2afb0c310"
      },
      "outputs": [],
      "source": [
        "#!pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.sklearn  # or mlflow.xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WgCgN7cV8uXB"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)  # Show all columns in the DataFrame\n",
        "pd.set_option('display.max_rows', None)     # Show all rows in the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S-iU5uG8zV1"
      },
      "source": [
        "###Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pHDe3BFb8wCA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('C:/Users/kemin/Documents/Projects/Telco-Customer-Churn/data/raw/Telco-Customer-Churn.csv')\n",
        "df1 = pd.read_csv(\"C:/Users/kemin/Documents/Projects/Telco-Customer-Churn/data/processed/telco_churn_processed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsWagqsb9AsX"
      },
      "source": [
        "###Preprocess and Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF-n05-I9DOu",
        "outputId": "16160d52-41db-4624-c75e-cfa6461dd297"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kemin\\AppData\\Local\\Temp\\ipykernel_15956\\2830485926.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[binary_cols] = df[binary_cols].replace({\n"
          ]
        }
      ],
      "source": [
        "# Binary categorical columns (2 unique values)\n",
        "binary_cols = [\n",
        "    'gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn'\n",
        "]\n",
        "\n",
        "# Map Yes/No and Male/Female to 0/1\n",
        "df[binary_cols] = df[binary_cols].replace({\n",
        "    'Yes': 1, 'No': 0,\n",
        "    'Male': 1, 'Female': 0\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "asUGuHYv9FHx"
      },
      "outputs": [],
      "source": [
        "# Categorical columns with > 2 unique values\n",
        "multi_cat_cols = [\n",
        "    'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
        "    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
        "    'Contract', 'PaymentMethod'\n",
        "]\n",
        "\n",
        "# One-hot encode\n",
        "df = pd.get_dummies(df, columns=multi_cat_cols, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DxmG8NrN9HCI"
      },
      "outputs": [],
      "source": [
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Lp-WcfO99JTU"
      },
      "outputs": [],
      "source": [
        "df = df.drop('customerID', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "I1QTBAf79Kjw"
      },
      "outputs": [],
      "source": [
        "bool_cols = df.select_dtypes(include='bool').columns\n",
        "df[bool_cols] = df[bool_cols].astype(int) # converts True/False to 1/0 for all boolean cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2OKA8pV9SOb"
      },
      "source": [
        "##Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bNUqbA39zMp"
      },
      "source": [
        "###Class Imbalence Problem & Business Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "Vxi5ZNsX9TYe",
        "outputId": "4077136e-0c7e-4ec0-8986-b65c149a12b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Churn\n",
              "0    5174\n",
              "1    1869\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Churn'].value_counts() #Class Imbalence Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKRtkwQS9anf"
      },
      "source": [
        "Business context\n",
        "Churn prediction is asymmetric in cost:\n",
        "\n",
        "- False Negative (FN): You predict a customer will not churn, but they actually leave → you miss the chance to intervene and keep them.\n",
        "\n",
        "- False Positive (FP): You predict a customer will churn, but they stay → you might spend some retention resources unnecessarily.\n",
        "\n",
        "- Missing churners (FN) usually costs more than wrongly targeting a loyal customer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPfxkcd99hrK"
      },
      "source": [
        "Priorities\n",
        "- If retention campaigns are cheap → prioritize recall (catch every possible churner).\n",
        "- If retention campaigns are expensive → balance precision and recall using F1 score\n",
        "- If business wants a ranking of churn risk → use ROC-AUC or PR-AUC to evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaqSxy2-9udi"
      },
      "source": [
        "###Prepare Data for ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FIzdmODh9Xqo"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "THRESHOLD = 0.3  # lower than 0.5 to boost recall (see next to choose the right value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvGWbdUG9928"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4F6RKz39_1Y",
        "outputId": "db6858eb-90de-48a9-a2fa-f08a4264a1fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.885     0.769     0.823      1035\n",
            "           1      0.531     0.725     0.613       374\n",
            "\n",
            "    accuracy                          0.757      1409\n",
            "   macro avg      0.708     0.747     0.718      1409\n",
            "weighted avg      0.791     0.757     0.767      1409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    class_weight='balanced',   # handles imbalance for you\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "proba = rf.predict_proba(X_test)[:, 1]\n",
        "y_pred = (proba >= THRESHOLD).astype(int)\n",
        "\n",
        "print(classification_report(y_test, y_pred, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bOsNZbv-KT7",
        "outputId": "3a1518ad-305b-441e-ee8f-1fe327613aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold tuning for RandomForest\n",
            "Thresh  Prec_1  Rec_1   F1_1    \n",
            "0.25    0.500   0.783   0.610   \n",
            "0.3     0.531   0.725   0.613   \n",
            "0.35    0.543   0.668   0.600   \n",
            "0.4     0.581   0.620   0.600   \n",
            "0.45    0.608   0.556   0.581   \n",
            "0.5     0.630   0.492   0.553   \n"
          ]
        }
      ],
      "source": [
        "proba = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Threshold tuning for RandomForest\")\n",
        "\n",
        "print(f\"{'Thresh':<8}{'Prec_1':<8}{'Rec_1':<8}{'F1_1':<8}\")\n",
        "for thresh in [0.25, 0.30, 0.35, 0.40, 0.45, 0.50]:\n",
        "    preds = (proba >= thresh).astype(int)\n",
        "    prec = precision_score(y_test, preds, pos_label=1)\n",
        "    rec = recall_score(y_test, preds, pos_label=1)\n",
        "    f1 = f1_score(y_test, preds, pos_label=1)\n",
        "    print(f\"{thresh:<8}{prec:<8.3f}{rec:<8.3f}{f1:<8.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6YSe5rn-NZS"
      },
      "source": [
        "###LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM2OexCF-PGT",
        "outputId": "d1b7acc2-8dd8-4d71-c622-86c9a7d78e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 1495, number of negative: 4139\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 637\n",
            "[LightGBM] [Info] Number of data points in the train set: 5634, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Training time: 0.84 seconds\n",
            "Prediction time: 0.0168 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.914     0.702     0.795      1035\n",
            "           1      0.498     0.818     0.619       374\n",
            "\n",
            "    accuracy                          0.733      1409\n",
            "   macro avg      0.706     0.760     0.707      1409\n",
            "weighted avg      0.804     0.733     0.748      1409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lgbm = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Training timer\n",
        "start_train = time.time()\n",
        "lgbm.fit(X_train, y_train)\n",
        "train_time = time.time() - start_train\n",
        "print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "# Prediction timer\n",
        "start_pred = time.time()\n",
        "proba = lgbm.predict_proba(X_test)[:, 1]\n",
        "y_pred = (proba >= THRESHOLD).astype(int)\n",
        "pred_time = time.time() - start_pred\n",
        "print(f\"Prediction time: {pred_time:.4f} seconds\")\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBlXoGZ9-nHr",
        "outputId": "3e30de4b-9a83-4dd6-f413-7f6f64844ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold tuning for LightGBM\n",
            "Thresh  Prec_1  Rec_1   F1_1    \n",
            "0.25    0.479   0.842   0.610   \n",
            "0.3     0.498   0.818   0.619   \n",
            "0.35    0.507   0.786   0.616   \n",
            "0.4     0.524   0.757   0.619   \n",
            "0.45    0.537   0.741   0.622   \n",
            "0.5     0.552   0.701   0.617   \n"
          ]
        }
      ],
      "source": [
        "proba = lgbm.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Threshold tuning for LightGBM\")\n",
        "\n",
        "print(f\"{'Thresh':<8}{'Prec_1':<8}{'Rec_1':<8}{'F1_1':<8}\")\n",
        "for thresh in [0.25, 0.30, 0.35, 0.40, 0.45, 0.50]:\n",
        "    preds = (proba >= thresh).astype(int)\n",
        "    prec = precision_score(y_test, preds, pos_label=1)\n",
        "    rec = recall_score(y_test, preds, pos_label=1)\n",
        "    f1 = f1_score(y_test, preds, pos_label=1)\n",
        "    print(f\"{thresh:<8}{prec:<8.3f}{rec:<8.3f}{f1:<8.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcuOGHNU-tXr"
      },
      "source": [
        "###XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "334zCXRo-vhI",
        "outputId": "a8f182f2-ed1c-471a-911c-014e3918627a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1.13 seconds\n",
            "Prediction time: 0.0160 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.910     0.684     0.781      1035\n",
            "           1      0.482     0.813     0.605       374\n",
            "\n",
            "    accuracy                          0.718      1409\n",
            "   macro avg      0.696     0.748     0.693      1409\n",
            "weighted avg      0.796     0.718     0.734      1409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate scale_pos_weight for imbalance\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "# Training timer\n",
        "start_train = time.time()\n",
        "xgb.fit(X_train, y_train)\n",
        "train_time = time.time() - start_train\n",
        "print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "# Prediction timer\n",
        "start_pred = time.time()\n",
        "proba = xgb.predict_proba(X_test)[:, 1]\n",
        "y_pred = (proba >= THRESHOLD).astype(int)\n",
        "pred_time = time.time() - start_pred\n",
        "print(f\"Prediction time: {pred_time:.4f} seconds\")\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX_Ro1-w-3vC",
        "outputId": "8ffa896c-6775-465b-f3ab-59ef26e66068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold tuning for XGBoost\n",
            "Thresh  Prec_1  Rec_1   F1_1    \n",
            "0.25    0.467   0.837   0.600   \n",
            "0.3     0.482   0.813   0.605   \n",
            "0.35    0.499   0.781   0.609   \n",
            "0.4     0.513   0.751   0.610   \n",
            "0.45    0.535   0.719   0.613   \n",
            "0.5     0.546   0.698   0.613   \n"
          ]
        }
      ],
      "source": [
        "proba = xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Threshold tuning for XGBoost\")\n",
        "\n",
        "print(f\"{'Thresh':<8}{'Prec_1':<8}{'Rec_1':<8}{'F1_1':<8}\")\n",
        "for thresh in [0.25, 0.30, 0.35, 0.40, 0.45, 0.50]:\n",
        "    preds = (proba >= thresh).astype(int)\n",
        "    prec = precision_score(y_test, preds, pos_label=1)\n",
        "    rec = recall_score(y_test, preds, pos_label=1)\n",
        "    f1 = f1_score(y_test, preds, pos_label=1)\n",
        "    print(f\"{thresh:<8}{prec:<8.3f}{rec:<8.3f}{f1:<8.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eaS_MuH-65a"
      },
      "source": [
        "###Model Choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1w4Zz0u-85l"
      },
      "source": [
        "XGBoost is the best model\n",
        "- Gives a decent recall (same as LightGBM)\n",
        "- faster to train (3x faster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwhI5Jjg_H_6"
      },
      "source": [
        "###Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYiwu_R1_KNe",
        "outputId": "d22960ee-3721-4b92-c5d0-9c09ebe3b727"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-01-14 11:16:18,418] A new study created in memory with name: no-name-d8a1779b-d075-4915-8de2-82b9644f6efd\n",
            "[I 2026-01-14 11:16:19,125] Trial 0 finished with value: 0.8743315508021391 and parameters: {'n_estimators': 700, 'learning_rate': 0.07459827040758736, 'max_depth': 4, 'subsample': 0.5338754702767036, 'colsample_bytree': 0.7850991612381718, 'min_child_weight': 2, 'gamma': 2.781805878464076, 'reg_alpha': 1.683502527983201, 'reg_lambda': 0.6073138937326578}. Best is trial 0 with value: 0.8743315508021391.\n",
            "[I 2026-01-14 11:16:19,724] Trial 1 finished with value: 0.8770053475935828 and parameters: {'n_estimators': 521, 'learning_rate': 0.04925030542667354, 'max_depth': 7, 'subsample': 0.7337676654721472, 'colsample_bytree': 0.6905392264029526, 'min_child_weight': 3, 'gamma': 2.1849996936535505, 'reg_alpha': 2.0980464257675364, 'reg_lambda': 0.8450985493460283}. Best is trial 1 with value: 0.8770053475935828.\n",
            "[I 2026-01-14 11:16:20,606] Trial 2 finished with value: 0.8556149732620321 and parameters: {'n_estimators': 722, 'learning_rate': 0.08623581739086734, 'max_depth': 7, 'subsample': 0.8206438958259789, 'colsample_bytree': 0.7912268987688809, 'min_child_weight': 7, 'gamma': 0.696608768412682, 'reg_alpha': 4.196709555987528, 'reg_lambda': 3.243773641404875}. Best is trial 1 with value: 0.8770053475935828.\n",
            "[I 2026-01-14 11:16:21,474] Trial 3 finished with value: 0.8181818181818182 and parameters: {'n_estimators': 453, 'learning_rate': 0.15781829554461088, 'max_depth': 9, 'subsample': 0.7006634445203325, 'colsample_bytree': 0.9419987256519149, 'min_child_weight': 1, 'gamma': 1.1699279746625497, 'reg_alpha': 2.4392256532898577, 'reg_lambda': 2.1973985512605942}. Best is trial 1 with value: 0.8770053475935828.\n",
            "[I 2026-01-14 11:16:22,289] Trial 4 finished with value: 0.8502673796791443 and parameters: {'n_estimators': 779, 'learning_rate': 0.09479301639137992, 'max_depth': 7, 'subsample': 0.8922848046722052, 'colsample_bytree': 0.7648452204994479, 'min_child_weight': 9, 'gamma': 0.7809453738829186, 'reg_alpha': 2.7554350085973716, 'reg_lambda': 2.8990076135904785}. Best is trial 1 with value: 0.8770053475935828.\n",
            "[I 2026-01-14 11:16:22,814] Trial 5 finished with value: 0.8582887700534759 and parameters: {'n_estimators': 378, 'learning_rate': 0.1543189109875076, 'max_depth': 4, 'subsample': 0.6096909642890349, 'colsample_bytree': 0.681862260213405, 'min_child_weight': 9, 'gamma': 0.38948221698304863, 'reg_alpha': 4.273081942701832, 'reg_lambda': 3.8221785263010344}. Best is trial 1 with value: 0.8770053475935828.\n",
            "[I 2026-01-14 11:16:23,343] Trial 6 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 748, 'learning_rate': 0.11714626077319813, 'max_depth': 10, 'subsample': 0.7829018006942798, 'colsample_bytree': 0.5665865670243699, 'min_child_weight': 1, 'gamma': 4.819712864054145, 'reg_alpha': 3.2971722753772505, 'reg_lambda': 0.6108591050295453}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:23,684] Trial 7 finished with value: 0.8957219251336899 and parameters: {'n_estimators': 341, 'learning_rate': 0.12434428304725344, 'max_depth': 4, 'subsample': 0.5895927940757582, 'colsample_bytree': 0.9353407822906279, 'min_child_weight': 8, 'gamma': 4.557327347242709, 'reg_alpha': 0.24011069154572018, 'reg_lambda': 2.0495700438114186}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:24,347] Trial 8 finished with value: 0.8475935828877005 and parameters: {'n_estimators': 308, 'learning_rate': 0.04996409858486942, 'max_depth': 8, 'subsample': 0.8024983478264411, 'colsample_bytree': 0.9200772138334437, 'min_child_weight': 5, 'gamma': 0.13808240139297323, 'reg_alpha': 2.5482579913938475, 'reg_lambda': 1.5390301362073782}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:24,728] Trial 9 finished with value: 0.9064171122994652 and parameters: {'n_estimators': 473, 'learning_rate': 0.05311554837429878, 'max_depth': 9, 'subsample': 0.7402421359634438, 'colsample_bytree': 0.5073781128315689, 'min_child_weight': 5, 'gamma': 4.9669113453648555, 'reg_alpha': 1.063661507469012, 'reg_lambda': 3.4152175922688723}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:25,123] Trial 10 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 634, 'learning_rate': 0.19893040007819335, 'max_depth': 10, 'subsample': 0.9701054786903589, 'colsample_bytree': 0.5109655473908508, 'min_child_weight': 3, 'gamma': 3.779463708987773, 'reg_alpha': 3.388144420220501, 'reg_lambda': 0.04911198304880937}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:25,574] Trial 11 finished with value: 0.9064171122994652 and parameters: {'n_estimators': 626, 'learning_rate': 0.19329722708257419, 'max_depth': 10, 'subsample': 0.9902071664541628, 'colsample_bytree': 0.5262201671728728, 'min_child_weight': 3, 'gamma': 3.7690122887241055, 'reg_alpha': 3.4781838285307174, 'reg_lambda': 0.30239510307113704}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:26,255] Trial 12 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 617, 'learning_rate': 0.014530509115616208, 'max_depth': 10, 'subsample': 0.9771601655328201, 'colsample_bytree': 0.5894476943757802, 'min_child_weight': 1, 'gamma': 3.8976283646141487, 'reg_alpha': 3.4959122251555663, 'reg_lambda': 0.07547613530101699}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:26,765] Trial 13 finished with value: 0.9064171122994652 and parameters: {'n_estimators': 797, 'learning_rate': 0.19818791126597368, 'max_depth': 10, 'subsample': 0.9026745997385568, 'colsample_bytree': 0.5972483678267158, 'min_child_weight': 3, 'gamma': 3.6604136667091582, 'reg_alpha': 4.866787863645733, 'reg_lambda': 4.6530313699120915}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:27,269] Trial 14 finished with value: 0.8957219251336899 and parameters: {'n_estimators': 631, 'learning_rate': 0.13313618474539846, 'max_depth': 9, 'subsample': 0.8906584126920912, 'colsample_bytree': 0.5888574315842353, 'min_child_weight': 4, 'gamma': 2.9248502960173504, 'reg_alpha': 3.265295151042688, 'reg_lambda': 1.1747455208463597}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:27,932] Trial 15 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 698, 'learning_rate': 0.16570494597865298, 'max_depth': 6, 'subsample': 0.6698342276859447, 'colsample_bytree': 0.6641995571103875, 'min_child_weight': 1, 'gamma': 4.3703798204568, 'reg_alpha': 4.076752485554474, 'reg_lambda': 1.50647456042553}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:28,367] Trial 16 finished with value: 0.8983957219251337 and parameters: {'n_estimators': 571, 'learning_rate': 0.11324859249396152, 'max_depth': 8, 'subsample': 0.8183164527315321, 'colsample_bytree': 0.5004016422799404, 'min_child_weight': 6, 'gamma': 3.3488989570199297, 'reg_alpha': 3.129993277303769, 'reg_lambda': 0.13952199773749013}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:28,882] Trial 17 finished with value: 0.8877005347593583 and parameters: {'n_estimators': 745, 'learning_rate': 0.14117385299514285, 'max_depth': 6, 'subsample': 0.9494177916042429, 'colsample_bytree': 0.5555916671799481, 'min_child_weight': 2, 'gamma': 2.1346937275280458, 'reg_alpha': 1.600202542937341, 'reg_lambda': 0.9633344902428306}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:29,319] Trial 18 finished with value: 0.9064171122994652 and parameters: {'n_estimators': 662, 'learning_rate': 0.17817747077131213, 'max_depth': 8, 'subsample': 0.8478820838299856, 'colsample_bytree': 0.8438339319265762, 'min_child_weight': 4, 'gamma': 4.926069594192382, 'reg_alpha': 3.86056028573119, 'reg_lambda': 1.7957181750997515}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:29,815] Trial 19 finished with value: 0.9090909090909091 and parameters: {'n_estimators': 556, 'learning_rate': 0.17850584068945902, 'max_depth': 5, 'subsample': 0.6478627199403746, 'colsample_bytree': 0.6236628710607987, 'min_child_weight': 2, 'gamma': 4.233746593521328, 'reg_alpha': 4.592790472324554, 'reg_lambda': 0.6729317799771403}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:30,643] Trial 20 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 668, 'learning_rate': 0.016653512570888124, 'max_depth': 9, 'subsample': 0.9292775546957992, 'colsample_bytree': 0.7274100217946752, 'min_child_weight': 4, 'gamma': 3.3329686048307634, 'reg_alpha': 2.9787421810868175, 'reg_lambda': 2.5813512670277534}. Best is trial 6 with value: 0.9117647058823529.\n",
            "[I 2026-01-14 11:16:31,540] Trial 21 finished with value: 0.9171122994652406 and parameters: {'n_estimators': 581, 'learning_rate': 0.010785357560312986, 'max_depth': 10, 'subsample': 0.981807143778469, 'colsample_bytree': 0.5589221036317655, 'min_child_weight': 1, 'gamma': 4.006822656756029, 'reg_alpha': 3.6142462010701544, 'reg_lambda': 0.0005828221690062918}. Best is trial 21 with value: 0.9171122994652406.\n",
            "[I 2026-01-14 11:16:32,067] Trial 22 finished with value: 0.9090909090909091 and parameters: {'n_estimators': 511, 'learning_rate': 0.03642306092417032, 'max_depth': 10, 'subsample': 0.950869766296118, 'colsample_bytree': 0.6335670068180931, 'min_child_weight': 1, 'gamma': 4.2322488580994815, 'reg_alpha': 3.7204954847865244, 'reg_lambda': 0.4622213526564175}. Best is trial 21 with value: 0.9171122994652406.\n",
            "[I 2026-01-14 11:16:32,551] Trial 23 finished with value: 0.9037433155080213 and parameters: {'n_estimators': 588, 'learning_rate': 0.06872083543063576, 'max_depth': 10, 'subsample': 0.774904549001228, 'colsample_bytree': 0.5437225640446155, 'min_child_weight': 2, 'gamma': 4.611689448104632, 'reg_alpha': 2.991391740557549, 'reg_lambda': 1.1890199266869033}. Best is trial 21 with value: 0.9171122994652406.\n",
            "[I 2026-01-14 11:16:33,101] Trial 24 finished with value: 0.893048128342246 and parameters: {'n_estimators': 755, 'learning_rate': 0.10244871117420844, 'max_depth': 9, 'subsample': 0.860486933836847, 'colsample_bytree': 0.9996777131507082, 'min_child_weight': 3, 'gamma': 3.9819542426422885, 'reg_alpha': 2.102589533388353, 'reg_lambda': 0.0001876029060863607}. Best is trial 21 with value: 0.9171122994652406.\n",
            "[I 2026-01-14 11:16:33,470] Trial 25 finished with value: 0.9144385026737968 and parameters: {'n_estimators': 450, 'learning_rate': 0.12074232029272004, 'max_depth': 3, 'subsample': 0.935162039890772, 'colsample_bytree': 0.5633960161656449, 'min_child_weight': 1, 'gamma': 3.3428651410071812, 'reg_alpha': 4.546778144531409, 'reg_lambda': 0.4391334152446648}. Best is trial 21 with value: 0.9171122994652406.\n",
            "[I 2026-01-14 11:16:33,836] Trial 26 finished with value: 0.9224598930481284 and parameters: {'n_estimators': 420, 'learning_rate': 0.12105134838892777, 'max_depth': 3, 'subsample': 0.9946570983423584, 'colsample_bytree': 0.5617518784757857, 'min_child_weight': 1, 'gamma': 3.2328515123225703, 'reg_alpha': 4.979554238456605, 'reg_lambda': 0.5805809284683919}. Best is trial 26 with value: 0.9224598930481284.\n",
            "[I 2026-01-14 11:16:34,155] Trial 27 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 403, 'learning_rate': 0.13964001931916353, 'max_depth': 3, 'subsample': 0.9939182717844045, 'colsample_bytree': 0.6271178364284016, 'min_child_weight': 10, 'gamma': 1.7305207418509616, 'reg_alpha': 4.903609445155935, 'reg_lambda': 1.2281923407098967}. Best is trial 26 with value: 0.9224598930481284.\n",
            "[I 2026-01-14 11:16:34,509] Trial 28 finished with value: 0.9090909090909091 and parameters: {'n_estimators': 441, 'learning_rate': 0.08198536002136525, 'max_depth': 3, 'subsample': 0.9345232475328877, 'colsample_bytree': 0.6519495982984588, 'min_child_weight': 2, 'gamma': 3.163337176029032, 'reg_alpha': 4.451166672136747, 'reg_lambda': 0.43503939826347526}. Best is trial 26 with value: 0.9224598930481284.\n",
            "[I 2026-01-14 11:16:35,222] Trial 29 finished with value: 0.893048128342246 and parameters: {'n_estimators': 500, 'learning_rate': 0.10230538662952154, 'max_depth': 5, 'subsample': 0.5217617869622637, 'colsample_bytree': 0.7196466005230735, 'min_child_weight': 1, 'gamma': 2.7223093575282538, 'reg_alpha': 4.664491789197758, 'reg_lambda': 0.7167882128034113}. Best is trial 26 with value: 0.9224598930481284.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Params: {'n_estimators': 420, 'learning_rate': 0.12105134838892777, 'max_depth': 3, 'subsample': 0.9946570983423584, 'colsample_bytree': 0.5617518784757857, 'min_child_weight': 1, 'gamma': 3.2328515123225703, 'reg_alpha': 4.979554238456605, 'reg_lambda': 0.5805809284683919}\n",
            "Best Recall: 0.9224598930481284\n"
          ]
        }
      ],
      "source": [
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 800),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 5),\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1,\n",
        "        \"scale_pos_weight\": (y_train == 0).sum() / (y_train == 1).sum(),\n",
        "        \"eval_metric\": \"logloss\"\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    proba = model.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (proba >= THRESHOLD).astype(int)  # Keep your tuned threshold\n",
        "    return recall_score(y_test, y_pred, pos_label=1)  # Optimize recall for churners\n",
        "\n",
        "# Run Optuna\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Best Params:\", study.best_params)\n",
        "print(\"Best Recall:\", study.best_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5f_kpL2_ViW",
        "outputId": "3f0a775c-9de7-44ff-e9c1-0bcebae0b0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.30 seconds\n",
            "Prediction time: 0.0106 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.952     0.560     0.706      1035\n",
            "           1      0.431     0.922     0.588       374\n",
            "\n",
            "    accuracy                          0.656      1409\n",
            "   macro avg      0.692     0.741     0.647      1409\n",
            "weighted avg      0.814     0.656     0.674      1409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate scale_pos_weight for imbalance\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "# Add the scale_pos_weight and fixed params to the best ones from Optuna\n",
        "best_params = study.best_params\n",
        "best_params.update({\n",
        "    \"random_state\": 42,\n",
        "    \"n_jobs\": -1,\n",
        "    \"scale_pos_weight\": scale_pos_weight,\n",
        "    \"eval_metric\": \"logloss\"\n",
        "})\n",
        "\n",
        "# Create model from best params\n",
        "xgb = XGBClassifier(**best_params)\n",
        "\n",
        "# Training timer\n",
        "start_train = time.time()\n",
        "xgb.fit(X_train, y_train)\n",
        "train_time = time.time() - start_train\n",
        "print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "# Prediction timer\n",
        "start_pred = time.time()\n",
        "proba = xgb.predict_proba(X_test)[:, 1]\n",
        "y_pred = (proba >= THRESHOLD).astype(int)\n",
        "pred_time = time.time() - start_pred\n",
        "print(f\"Prediction time: {pred_time:.4f} seconds\")\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfFuQT9y_l19"
      },
      "source": [
        "###MLFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vOeArdo6_nhG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/14 11:17:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.952     0.560     0.706      1035\n",
            "           1      0.431     0.922     0.588       374\n",
            "\n",
            "    accuracy                          0.656      1409\n",
            "   macro avg      0.692     0.741     0.647      1409\n",
            "weighted avg      0.814     0.656     0.674      1409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Force MLflow to always use the project root's mlruns folder\n",
        "PROJECT_ROOT = Path.cwd().parent  # current notebook directory\n",
        "mlflow.set_tracking_uri(PROJECT_ROOT / \"mlruns\")\n",
        "mlflow.set_experiment(\"Telco Churn - XGBoost\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "    # Calculate scale_pos_weight\n",
        "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "    # Best params from Optuna\n",
        "    best_params = study.best_params\n",
        "    best_params.update({\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1,\n",
        "        \"scale_pos_weight\": scale_pos_weight,\n",
        "        \"eval_metric\": \"logloss\"\n",
        "    })\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(best_params)\n",
        "\n",
        "    # Training timer\n",
        "    start_train = time.time()\n",
        "    xgb = XGBClassifier(**best_params)\n",
        "    xgb.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_train\n",
        "    mlflow.log_metric(\"train_time\", train_time)\n",
        "\n",
        "    # Prediction\n",
        "    start_pred = time.time()\n",
        "    proba = xgb.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (proba >= THRESHOLD).astype(int)\n",
        "    pred_time = time.time() - start_pred\n",
        "    mlflow.log_metric(\"pred_time\", pred_time)\n",
        "\n",
        "    # Metrics\n",
        "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "    auc = roc_auc_score(y_test, proba)\n",
        "\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"f1\", f1)\n",
        "    mlflow.log_metric(\"roc_auc\", auc)\n",
        "\n",
        "    # Save model\n",
        "    mlflow.xgboost.log_model(xgb, \"model\")\n",
        "\n",
        "    print(classification_report(y_test, y_pred, digits=3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-S-iU5uG8zV1",
        "QsWagqsb9AsX",
        "5bNUqbA39zMp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
